{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18886,
     "status": "ok",
     "timestamp": 1611088144397,
     "user": {
      "displayName": "Georgios Tzimiropoulos",
      "photoUrl": "",
      "userId": "03131831684678803743"
     },
     "user_tz": 0
    },
    "id": "CBRXrM4yVbRK",
    "outputId": "42aefd2d-11cd-40e3-f955-3dd3c55830f7",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Setting up google drive \\nfrom google.colab import drive\\ndrive.mount('/content/gdrive', force_remount=True)\\nimport sys\\nsys.path.append('/content/gdrive/MyDrive/Colab Notebooks')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Setting up google drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "import sys\n",
    "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4851,
     "status": "ok",
     "timestamp": 1611088154442,
     "user": {
      "displayName": "Georgios Tzimiropoulos",
      "photoUrl": "",
      "userId": "03131831684678803743"
     },
     "user_tz": 0
    },
    "id": "8o6vaVOzVZd8",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import my_utils as mu\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOufsvkIVZeE",
    "origin_pos": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks -- ImageNet\n",
    "\n",
    "* Deep models with many layers require large amounts of data in order to significantly outperform traditional methods (e.g., linear and kernel methods).\n",
    "* Most research up until 2010 relied on tiny datasets.\n",
    "\n",
    "* In 2009, the ImageNet dataset was released, challenging researchers to learn models from 1 million examples, 1,000 each from 1,000 distinct categories of objects.\n",
    "    * This scale was unprecedented.\n",
    "    * The associated competition, dubbed the ImageNet Challenge pushed computer vision and machine learning research forward, challenging researchers to identify which models performed best at a greater scale than academics had previously considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRoxGCZTVZeF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks -- GPU Processing\n",
    "\n",
    "* Training Deep learning models can take hundreds of epochs, and each iteration requires passing data through many layers of computationally-expensive linear algebra operations.\n",
    "* This is one of the main reasons why in the 90s and early 2000s, simple algorithms based on linear and kernel methods were preferred.\n",
    "* Graphical processing units (GPUs) proved to be a game changer in make deep learning feasible.\n",
    "     * Orginally optimized for high throughput 4x4 matrix-vector products for  graphics tasks.\n",
    "     * strikingly similar to what is required to calculate convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Back to 2012: A major breakthrough came when Alex Krizhevsky and Ilya Sutskever implemented a deep convolutional neural network that could run on GPU hardware.\n",
    "    * They realized that the computational bottlenecks in CNNs (convolutions and matrix multiplications) are all operations that could be parallelized in hardware.\n",
    "* Using two NVIDIA GTX 580s with 3GB of memory, they implemented fast convolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEWBiMXTVZeF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# AlexNet\n",
    "\n",
    "* AlexNet was introduced in 2012, named after Alex Krizhevsky, the first author of the breakthrough ImageNet classification paper  \n",
    "    * It won the ImageNet Large Scale Visual Recognition Challenge 2012 by a phenomenally large margin.\n",
    "\n",
    "* The architectures of AlexNet and LeNet are *very similar*\n",
    "* There are also significant differences.\n",
    "    * First, AlexNet is much deeper than the comparatively small LeNet5.\n",
    "    * Second, AlexNet used the ReLU instead of the sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxZjEnaBVZeF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# AlexNet\n",
    "\n",
    "![LeNet (left) and AlexNet (right)](img/alexnet.svg)\n",
    "\n",
    "<!-- ![LeNet (left) and AlexNet (right)](https://drive.google.com/uc?export=view&id=1sAHdepTD1zhe8sF-0tl1eQqU3iTjAULT) -->   \n",
    "\n",
    "* LeNet (left) and AlexNet (right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjAt1Ts6VZeG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concise Implementation of LeNet\n",
    "\n",
    "* Goal: use high-level APIs of PyTorch for implementing LeNet for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training and test data\n",
    "batch_size = 256\n",
    "train_iter, test_iter = mu.load_data_fashion_mnist(batch_size, resize=224)\n",
    "# type(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCLNk35LVZeG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1611088176416,
     "user": {
      "displayName": "Georgios Tzimiropoulos",
      "photoUrl": "",
      "userId": "03131831684678803743"
     },
     "user_tz": 0
    },
    "id": "FQ3zqSxgVZeH",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class AlexNet(torch.nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 96, 11, stride=4)\n",
    "        self.rl1 = nn.ReLU() \n",
    "        self.max1 = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5, stride=1, padding=2)\n",
    "        self.rl2 = nn.ReLU() \n",
    "        self.max2 = nn.MaxPool2d(3, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(256, 384, 3, 1, padding=1)\n",
    "        self.rl3 = nn.ReLU() \n",
    "        self.conv4 = nn.Conv2d(384, 384, 3, 1, padding=1)\n",
    "        self.rl4 = nn.ReLU() \n",
    "        self.conv5 = nn.Conv2d(384, 384, 3, 1, padding=1)\n",
    "        self.rl5 = nn.ReLU() \n",
    "        self.max3 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.fl = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(9600, 4096)\n",
    "        self.rl6 = nn.ReLU() \n",
    "        self.linear2 = nn.Linear(4096, 4096)\n",
    "        self.rl7 = nn.ReLU() \n",
    "        self.linear3 = nn.Linear(4096, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        out = self.conv1(x)\n",
    "        print(out.size())\n",
    "        out = self.rl1(out)\n",
    "        out = self.max1(out)\n",
    "        print(out.size())\n",
    "        out = self.conv2(out)\n",
    "        print(out.size())\n",
    "        out = self.rl2(out)\n",
    "        out = self.max2(out)\n",
    "        print(out.size())\n",
    "        out = self.conv3(out)\n",
    "        print(out.size())\n",
    "        out = self.rl3(out)\n",
    "        out = self.conv4(out)\n",
    "        print(out.size())\n",
    "        out = self.rl4(out)\n",
    "        out = self.conv5(out)\n",
    "        print(out.size())\n",
    "        out = self.rl5(out)\n",
    "        out = self.max3(out)\n",
    "        print(out.size())\n",
    "\n",
    "        out = self.fl(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.rl6(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.rl7(out)\n",
    "        out = self.linear3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv1): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (rl1): ReLU()\n",
      "  (max1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (rl2): ReLU()\n",
      "  (max2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (rl3): ReLU()\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (rl4): ReLU()\n",
      "  (conv5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (rl5): ReLU()\n",
      "  (max3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fl): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=9600, out_features=4096, bias=True)\n",
      "  (rl6): ReLU()\n",
      "  (linear2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (rl7): ReLU()\n",
      "  (linear3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d: # by checking type we can init different layers in different ways\n",
    "        torch.nn.init.xavier_uniform_(m.weight)          \n",
    "\n",
    "num_outputs = 1000\n",
    "net = AlexNet(num_outputs)\n",
    "\n",
    "net.apply(init_weights);\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 224, 224])\n",
      "torch.Size([16, 96, 54, 54])\n",
      "torch.Size([16, 96, 26, 26])\n",
      "torch.Size([16, 256, 26, 26])\n",
      "torch.Size([16, 256, 12, 12])\n",
      "torch.Size([16, 384, 12, 12])\n",
      "torch.Size([16, 384, 12, 12])\n",
      "torch.Size([16, 384, 12, 12])\n",
      "torch.Size([16, 384, 5, 5])\n",
      "torch.Size([16, 1000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(16, 1, 224, 224)\n",
    "out = net(a)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwXdo4KCVZeK",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loss and Optimization Algorithm\n",
    "* As in Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1611088200823,
     "user": {
      "displayName": "Georgios Tzimiropoulos",
      "photoUrl": "",
      "userId": "03131831684678803743"
     },
     "user_tz": 0
    },
    "id": "M-CmngurVZeK"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jvc-s6zNVZeL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training\n",
    "\n",
    "* Use `my_utils.train_ch3` as in Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ab26Ezc_VZeL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n",
      "torch.Size([256, 1, 224, 224])\n",
      "torch.Size([256, 96, 54, 54])\n",
      "torch.Size([256, 96, 26, 26])\n",
      "torch.Size([256, 256, 26, 26])\n",
      "torch.Size([256, 256, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 12, 12])\n",
      "torch.Size([256, 384, 5, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ch3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter Stuff\\my_utils.py:325\u001b[0m, in \u001b[0;36mtrain_ch3\u001b[1;34m(net, train_iter, test_iter, loss, num_epochs, updater)\u001b[0m\n\u001b[0;32m    322\u001b[0m animator \u001b[38;5;241m=\u001b[39m Animator(xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, xlim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, num_epochs], ylim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.9\u001b[39m],\n\u001b[0;32m    323\u001b[0m                     legend\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest acc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 325\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch_ch3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m evaluate_accuracy(net, test_iter)\n\u001b[0;32m    327\u001b[0m     animator\u001b[38;5;241m.\u001b[39madd(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, train_metrics \u001b[38;5;241m+\u001b[39m (test_acc,))\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter Stuff\\my_utils.py:265\u001b[0m, in \u001b[0;36mtrain_epoch_ch3\u001b[1;34m(net, train_iter, loss, updater)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(updater, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer):\n\u001b[0;32m    264\u001b[0m     updater\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 265\u001b[0m     \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m     updater\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    267\u001b[0m     metric\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mfloat\u001b[39m(l) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(y), accuracy(y_hat, y),\n\u001b[0;32m    268\u001b[0m                y\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mnumel())\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x000002010BB09550> (for post_execute):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "mu.train_ch3(net, train_iter, test_iter, loss, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txyus2L-VZeM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VGG\n",
    "\n",
    "![Designing a network from building blocks.](img/vgg.svg) \n",
    "\n",
    "<!-- ![Designing a network from building blocks.](https://drive.google.com/uc?export=view&id=15ysfwZ-LbaSnZzd_lbeo2Iq5HYbR7WhY) -->   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9SsXuJeVZeM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VGG\n",
    "\n",
    "* Invented by the Visual Geometry Group in Oxford University\n",
    "* The original VGG network had 5 convolutional blocks (VGG blocks)\n",
    "    * The VGG block is the main building of the VGG network.\n",
    "    * The first two have one convolutional layer each.\n",
    "    * The latter three contain two convolutional layers each.\n",
    "    * The first block has 64 output channels and each subsequent block doubles the number of output channels, until that number reaches $512$.\n",
    "* Since this network uses $8$ convolutional layers and $3$ fully-connected layers, it is called VGG-11.\n",
    "    * The deepest network trained has 19 layers (called VGG-19)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IX7DyuEOVZeN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VGG block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1611088211165,
     "user": {
      "displayName": "Georgios Tzimiropoulos",
      "photoUrl": "",
      "userId": "03131831684678803743"
     },
     "user_tz": 0
    },
    "id": "6_HoAP9PVZeN"
   },
   "outputs": [],
   "source": [
    "class VGG_block(nn.Module):\n",
    "    def __init__(self, num_convs, input_channels, output_channels):\n",
    "        super(VGG_block, self).__init__()\n",
    "        self.num_convs = num_convs\n",
    "        for i in range(num_convs):\n",
    "            self.add_module('conv{0}'.format(i), nn.Conv2d(input_channels, \n",
    "                                                           output_channels, kernel_size=3, padding=1))\n",
    "            input_channels = output_channels\n",
    "            self.add_module('relu{0}'.format(i), nn.ReLU())\n",
    "            \n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i in range(self.num_convs):\n",
    "            out = self._modules['conv{0}'.format(i)](out)\n",
    "            out = self._modules['relu{0}'.format(i)](out)\n",
    "        \n",
    "        out = self.max_pool(out)\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG8qDbk4VZeO",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VGG-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1611088215996,
     "user": {
      "displayName": "Georgios Tzimiropoulos",
      "photoUrl": "",
      "userId": "03131831684678803743"
     },
     "user_tz": 0
    },
    "id": "ESV4CRRfVZeO"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, conv_arch):\n",
    "        super(VGG, self).__init__()\n",
    "        in_channels = 1\n",
    "        self.conv_arch = conv_arch\n",
    "        for i, (num_convs, out_channels) in enumerate(conv_arch):\n",
    "            self.add_module('vgg_block{0}'.format(i), VGG_block(num_convs, in_channels, out_channels))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.last = nn.Sequential(nn.Flatten(), nn.Linear(out_channels*7*7, 4096), \n",
    "                                  nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 4096), \n",
    "                                  nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i in range(len(self.conv_arch)):\n",
    "            out = self._modules['vgg_block{0}'.format(i)](out)\n",
    "        out = self.last(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "net = VGG(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13646,
     "status": "ok",
     "timestamp": 1611088233226,
     "user": {
      "displayName": "Georgios Tzimiropoulos",
      "photoUrl": "",
      "userId": "03131831684678803743"
     },
     "user_tz": 0
    },
    "id": "QNWLctZ4VZeO",
    "outputId": "3f432dd5-a09d-448b-b820-60cd8d79fce3",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.rand(16, 1, 224, 224)\n",
    "print(a.size())\n",
    "out = net(a)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pQXPV-dVZeP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ResNet\n",
    "* Prior to ResNet, it was hard to train very deep networks\n",
    "    * Depth facilitates learning very powerful networks\n",
    "* Kaiming He solved this in his paper: *Deep Residual Learning for Image Recognition,* CVPR 2016\n",
    "    * He showed how how to train networks with 152 convolutional layers!\n",
    "    * The most popular computer vision paper ever written!\n",
    "* Main idea: add the input feature $x$ to the output of a conv. layer $F$\n",
    "    * $y = F(x) + x$\n",
    "    * This is called **skip connection**\n",
    "* The advantage is that theres a direct path for propagating gradients during back-prop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ResNet block\n",
    "\n",
    "* ResNet is similar to VGG but uses a ResNet block which has a skip connection.\n",
    "    * The right block is used when the number of channels in the input is not the same as the number of channels in the output\n",
    "         * An $1 \\times 1$ conv. layer is used to make them equal.\n",
    "\n",
    "![Left: regular ResNet block; Right: ResNet block with 1x1 convolution](img/resnet-block.svg) \n",
    "\n",
    "<!-- ![Left: regular ResNet block; Right: ResNet block with 1x1 convolution.](https://drive.google.com/uc?export=view&id=1oKGT5iabWYLT7pUlMZOCX4-Drr3IttVZ)  -->  \n",
    "\n",
    "\n",
    "* Ignore BatchNorm for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Macro-Block\n",
    "\n",
    "* ResNet uses modules also called Macro-Blocks each of which containes several residual blocks. \n",
    "\n",
    "* In the first residual block within a Macro-Block, the number of channels is doubled compared with that of the previous module, and the height and width are halved.\n",
    "\n",
    "* In the remaining residual blocks, the number of channels remains the same\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E660w9QEVZeP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ResNet-18 -- Overview of architecture\n",
    "\n",
    "* We will consider here the implementation of the smallest ResNet, called ResNet-18.\n",
    "* ResNet-18 (and all other ResNets) has 1 stem and 4 macro-modules followed by 1 linear (FC) layer. \n",
    "* Stem = simple processing unit with 1 standard conv. layer (with stride 2) and 1 max pool (with stride 2).\n",
    "    * Reduces input resolution from 224 to 112 and then to 56.\n",
    "        * Nothing special so far.\n",
    "* Each macro-module processes features in a different resolution. \n",
    "     * Resolutions used are: 56, 28, 14, 7\n",
    "* The macro-modules are composed of the so-called **ResNet blocks**\n",
    "    * In ResNet-18, there are 2 ResNet blocks per macro-module\n",
    "* Each ResNet (Residual) block consists of 2 convolutions with skip connections\n",
    "    * Actually, the ResNet block is what He proposed in his paper  \n",
    "* In total $1 + 4\\times2\\times2 + 1=18$ layers\n",
    "    * That's why it's called ResNet-18\n",
    "    * Different blocks per macro-module results in different models like the 152-layer ResNet-152\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is4xltPIVZeS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Batch Normalization\n",
    "\n",
    "* Batch Normalization (BN) is a popular and effective technique that consistently accelerates the convergence of deep nets.\n",
    "* Together with residual blocks, BN made it possible to routinely train networks with over 100 layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A3gaUm4VZeS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Batch Normalization\n",
    "\n",
    "* Batch normalization is applied to individual layers and works as follows:\n",
    "    * In each training iteration (i.e. for each mini-batch), we normalize each channel of the input feature tensor seperately by subtracting their mean and dividing by their standard deviation (std).\n",
    "        * Mean and std are estimated based on the statistics of the current minibatch.\n",
    "    * Next, we apply a scaling coefficient and a scaling offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPt3KmeBVZeS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Batch Normalization\n",
    "\n",
    "\n",
    "* Denoting a particular minibatch by $\\mathcal{B}$, we firstly calculate $\\hat{\\mathbf{\\mu}}_\\mathcal{B}$ and $\\hat\\sigma_\\mathcal{B}$ as follows:\n",
    "$$\\hat{\\mathbf{\\mu}}_\\mathcal{B} \\leftarrow \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} \\mathbf{x}\n",
    "\\text{ and }\n",
    "\\hat{\\mathbf{\\sigma}}_\\mathcal{B}^2 \\leftarrow \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} (\\mathbf{x} - \\mathbf{\\mu}_{\\mathcal{B}})^2 + \\epsilon$$\n",
    "    * There's a different mean and std per channel.\n",
    "    * A small constant $\\epsilon > 0$ is added to ensure that we never attempt division by zero.\n",
    "\n",
    "* BN transforms the activations at a given feature tensor $\\mathbf{x}$\n",
    "according to the following expression:\n",
    "$$\\mathrm{BN}(\\mathbf{x}) = \\mathbf{\\gamma} \\odot \\frac{\\mathbf{x} - \\hat{\\mathbf{\\mu}}_\\mathcal{B}}{\\hat\\sigma_\\mathcal{B}} + \\mathbf{\\beta}$$\n",
    "   * The above formula is applied *channelwise* i.e. there's a different mean and std per channel.\n",
    "    \n",
    "* After normalization, the resulting minibatch of activations has zero mean and unit variance. Because this is an arbitrary choice, we commonly include channel-wise scaling coefficients $\\mathbf{\\gamma}$ and offsets $\\mathbf{\\beta}$.\n",
    "    * These are learnable parameters learnt via back-propagation!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "Advanced_CNNs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02d5001ca1d6448eba4138ff67ffe21d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0df4a2b1e36f435297e90b675deb5a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba3d1841ec9244b9b6b08cae98061acf",
       "IPY_MODEL_24ddce95d9ee44eeb33f22cd5c36e005"
      ],
      "layout": "IPY_MODEL_838cf4229c60428bb9f2a775b7ceb59f"
     }
    },
    "0f3e47a505714c2ab5c27588d91fc603": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18f803dfeca94025a09339adbd2045ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24ddce95d9ee44eeb33f22cd5c36e005": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c7d91d73c1f4de58cda1e9478153be7",
      "placeholder": "",
      "style": "IPY_MODEL_02d5001ca1d6448eba4138ff67ffe21d",
      "value": " 26427392/? [00:19&lt;00:00, 7016576.25it/s]"
     }
    },
    "30b6037cdfd045468b007ab949142289": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf938960595f44fab6c2928d007eb7e9",
      "placeholder": "",
      "style": "IPY_MODEL_6e769ee1cd804d608f645f93ff749bc9",
      "value": " 0/5148 [00:00&lt;?, ?it/s]"
     }
    },
    "3a481b1bd63b4390a379ce3222950980": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a999c0709db64678b0ad6f55311c2385",
      "placeholder": "",
      "style": "IPY_MODEL_9eca37bfb30a434e93db7021ffcc675e",
      "value": " 4423680/? [00:16&lt;00:00, 839184.54it/s]"
     }
    },
    "3c7d91d73c1f4de58cda1e9478153be7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4750296d17824226a2258083bdb2602e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49ccebd5dc8d45a183ce53f58fb85fa2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a0a12b921fd424bb046ea0c865ec6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bcea89387714af49c2a2cb2a0e7569d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8b8538072a3445894d670c387539588",
      "value": 1
     }
    },
    "4bad38fea9934c0aa70272cb412bc71e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5bcea89387714af49c2a2cb2a0e7569d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c14e595574747b8921109e5ab6ef135": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f45bbf912dd47a4ad57591be0959695": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b176c94c35e4f569359c5baad998611": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6e769ee1cd804d608f645f93ff749bc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "766fbe68cf594538b3d34836b47a01af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe5164cb8fba48088deeb4a360934f8f",
       "IPY_MODEL_30b6037cdfd045468b007ab949142289"
      ],
      "layout": "IPY_MODEL_4750296d17824226a2258083bdb2602e"
     }
    },
    "838cf4229c60428bb9f2a775b7ceb59f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89c004385203490cbe484e283ecfa9a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a0a12b921fd424bb046ea0c865ec6f7",
       "IPY_MODEL_be7b22855bff4e369d920ab4f7e4f0ce"
      ],
      "layout": "IPY_MODEL_18f803dfeca94025a09339adbd2045ed"
     }
    },
    "93a109eb962549949a0f7027030495dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9eca37bfb30a434e93db7021ffcc675e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a999c0709db64678b0ad6f55311c2385": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8b8538072a3445894d670c387539588": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ba3d1841ec9244b9b6b08cae98061acf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49ccebd5dc8d45a183ce53f58fb85fa2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bad38fea9934c0aa70272cb412bc71e",
      "value": 1
     }
    },
    "be7b22855bff4e369d920ab4f7e4f0ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d41078b074ed4bf094c870c65794d684",
      "placeholder": "",
      "style": "IPY_MODEL_93a109eb962549949a0f7027030495dd",
      "value": " 32768/? [00:16&lt;00:00, 115840.30it/s]"
     }
    },
    "c2ac9a050c7b4007a40f53ab29692d88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f3e47a505714c2ab5c27588d91fc603",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b176c94c35e4f569359c5baad998611",
      "value": 1
     }
    },
    "c8074d3690554d9d9e8efdb3405cdd4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cf938960595f44fab6c2928d007eb7e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d41078b074ed4bf094c870c65794d684": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4ed4d42d6b746609332e5d231d74f4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2ac9a050c7b4007a40f53ab29692d88",
       "IPY_MODEL_3a481b1bd63b4390a379ce3222950980"
      ],
      "layout": "IPY_MODEL_5f45bbf912dd47a4ad57591be0959695"
     }
    },
    "fe5164cb8fba48088deeb4a360934f8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c14e595574747b8921109e5ab6ef135",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8074d3690554d9d9e8efdb3405cdd4c",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
